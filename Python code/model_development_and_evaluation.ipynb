{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path1 = 'G:/共病/数据/multimorbidity_net_nodes_with_community_labels.csv'\n",
    "path2 = 'G:/eicu-crd/completed_data.csv'\n",
    "path3 = 'G:/eicu-crd/multimorbidity.csv'\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "df3 = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤1：创建ICD-10编码到社区的映射\n",
    "icd_to_community = pd.Series(df1.community.values, index=df1.id).to_dict()\n",
    "\n",
    "# 步骤2：定义一个函数来确定每个patientunitstayid的社区\n",
    "def determine_community(multimorbidity):\n",
    "    communities = set()\n",
    "    for icd_code in multimorbidity.split(','):\n",
    "        community = icd_to_community.get(icd_code.strip())\n",
    "        if community:\n",
    "            communities.add(str(community))  # 将社区编号转换为字符串\n",
    "    # 将社区合并为一个字符串，用逗号分隔\n",
    "    return ', '.join(sorted(communities))\n",
    "\n",
    "# 步骤3：应用函数到df3\n",
    "df3['community'] = df3['multimorbidity_icd10'].apply(determine_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd551941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine_learning_data = pd.merge(df3, df2, on='patientunitstayid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45274ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data = machine_learning_data[machine_learning_data['community'] != '']\n",
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用BMI\n",
    "machine_learning_data['BMI'] = machine_learning_data['weight'] / ((machine_learning_data['height'] / 100) ** 2)\n",
    "machine_learning_data = machine_learning_data.drop(columns=['height', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae525b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于医学专家的分箱\n",
    "machine_learning_data['age_category'] = pd.cut(machine_learning_data['age'],\n",
    "                                               bins=[0, 18, 40, 60, 80, 90, np.inf],\n",
    "                                               labels=['Children and Adolescents', 'Young Adults', 'Middle-aged', 'Senior', 'Elderly', 'Unknown'])\n",
    "machine_learning_data.drop(columns=['age'], inplace=True)\n",
    "machine_learning_data['BMI_category'] = pd.cut(machine_learning_data['BMI'],\n",
    "                                               bins=[-np.inf, 18.5, 24.9, 29.9, 34.9, 39.9, np.inf],\n",
    "                                               labels=['Underweight', 'Normal Weight', 'Overweight', 'Obesity Class I', 'Obesity Class II', 'Severe Obesity'])\n",
    "machine_learning_data.drop(columns=['BMI'], inplace=True)\n",
    "machine_learning_data['HLoS_category'] = pd.cut(machine_learning_data['HLoS'],\n",
    "                                                bins=[-np.inf, 3, 10, np.inf],\n",
    "                                                labels=['Short Stay', 'Medium Stay', 'Long Stay'])\n",
    "machine_learning_data.drop(columns=['HLoS'], inplace=True)\n",
    "machine_learning_data['ULoS_category'] = pd.cut(machine_learning_data['ULoS'],\n",
    "                                                bins=[-np.inf, 1, 3, np.inf],\n",
    "                                                labels=['Short Stay', 'Medium Stay', 'Long Stay'])\n",
    "machine_learning_data.drop(columns=['ULoS'], inplace=True)\n",
    "machine_learning_data['apachescore_category'] = pd.cut(machine_learning_data['apachescore'],\n",
    "                                                       bins=[-np.inf, 39, 69, np.inf],\n",
    "                                                       labels=['Mild', 'Moderate', 'Severe'])\n",
    "machine_learning_data.drop(columns=['apachescore'], inplace=True)\n",
    "machine_learning_data['SBP_category'] = pd.cut(machine_learning_data['SBP'],\n",
    "                                               bins=[-np.inf, 90, 120, 140, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['SBP'], inplace=True)\n",
    "machine_learning_data['DBP_category'] = pd.cut(machine_learning_data['DBP'],\n",
    "                                               bins=[-np.inf, 60, 80, 90, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['DBP'], inplace=True)\n",
    "machine_learning_data['MeanBP_category'] = pd.cut(machine_learning_data['MeanBP'],\n",
    "                                                  bins=[-np.inf, 65, 85, 100, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['MeanBP'], inplace=True)\n",
    "machine_learning_data['sao2_category'] = pd.cut(machine_learning_data['sao2'],\n",
    "                                                bins=[-np.inf, 95, 100],\n",
    "                                                labels=['Mild Hypoxemia', 'Normal'])\n",
    "machine_learning_data.drop(columns=['sao2'], inplace=True)\n",
    "machine_learning_data['heartrate_category'] = pd.cut(machine_learning_data['heartrate'],\n",
    "                                              bins=[-np.inf, 60, 100, 156, np.inf],\n",
    "                                              labels=['Bradycardia', 'Normal', 'Tachycardia', 'Extreme Tachycardia'])\n",
    "machine_learning_data.drop(columns=['heartrate'], inplace=True)\n",
    "machine_learning_data['respiration_category'] = pd.cut(machine_learning_data['respiration'],\n",
    "                                              bins=[-np.inf, 12, 20, 38, np.inf],\n",
    "                                              labels=['Bradypnea', 'Normal', 'Tachypnea', 'Extreme Tachypnea'])\n",
    "machine_learning_data.drop(columns=['respiration'], inplace=True)\n",
    "machine_learning_data['gcsscore_category'] = pd.cut(machine_learning_data['gcsscore'],\n",
    "                                               bins=[-np.inf, 7, 13, 15],\n",
    "                                               labels=['Severe Coma', 'Moderate Coma', 'Alert'])\n",
    "machine_learning_data.drop(columns=['gcsscore'], inplace=True)\n",
    "machine_learning_data['Urine_category'] = pd.cut(machine_learning_data['Urine'],\n",
    "                                              bins=[-np.inf, 500, 1477, np.inf],\n",
    "                                              labels=['Low Output', 'Normal', 'High Output'])\n",
    "machine_learning_data.drop(columns=['Urine'], inplace=True)\n",
    "machine_learning_data['BUN_category'] = pd.cut(machine_learning_data['BUN'],\n",
    "                                               bins=[-np.inf, 20, 83, np.inf],\n",
    "                                               labels=['Normal', 'Elevated', 'Very High'])\n",
    "machine_learning_data.drop(columns=['BUN'], inplace=True)\n",
    "machine_learning_data['Hct_category'] = pd.cut(machine_learning_data['Hct'],\n",
    "                                               bins=[-np.inf, 37, 50, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['Hct'], inplace=True)\n",
    "def hgb_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [2, 11, 16, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [2, 11, 15, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['Hgb']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['Hgb_category'] = machine_learning_data.apply(hgb_category, axis=1)\n",
    "machine_learning_data.drop(columns=['Hgb'], inplace=True)\n",
    "machine_learning_data['MCH_category'] = pd.cut(machine_learning_data['MCH'],\n",
    "                                               bins=[-np.inf, 27, 32, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCH'], inplace=True)\n",
    "machine_learning_data['MCHC_category'] = pd.cut(machine_learning_data['MCHC'],\n",
    "                                                bins=[-np.inf, 32, 36, np.inf],\n",
    "                                                labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCHC'], inplace=True)\n",
    "machine_learning_data['MCV_category'] = pd.cut(machine_learning_data['MCV'],\n",
    "                                               bins=[-np.inf, 86, 98, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCV'], inplace=True)\n",
    "machine_learning_data['MPV_category'] = pd.cut(machine_learning_data['MPV'],\n",
    "                                               bins=[-np.inf, 8, 12, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MPV'], inplace=True)\n",
    "def rbc_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [0.7, 3.1, 5.4, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [0.7, 3.2, 4.8, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['RBC']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['RBC_category'] = machine_learning_data.apply(rbc_category, axis=1)\n",
    "machine_learning_data.drop(columns=['RBC'], inplace=True)\n",
    "machine_learning_data['RDW_category'] = pd.cut(machine_learning_data['RDW'],\n",
    "                                               bins=[-np.inf, 13, np.inf],\n",
    "                                               labels=['Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['RDW'], inplace=True)\n",
    "machine_learning_data['WBC_category'] = pd.cut(machine_learning_data['WBC'],\n",
    "                                               bins=[-np.inf, 4, 10, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['WBC'], inplace=True)\n",
    "machine_learning_data['AnionGap_category'] = pd.cut(machine_learning_data['AnionGap'],\n",
    "                                              bins=[-np.inf, 7, 16, np.inf],\n",
    "                                              labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['AnionGap'], inplace=True)\n",
    "machine_learning_data['BG_category'] = pd.cut(machine_learning_data['BG'],\n",
    "                                              bins=[-np.inf, 70, 140, np.inf],\n",
    "                                              labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['BG'], inplace=True)\n",
    "machine_learning_data['bicarbonate_category'] = pd.cut(machine_learning_data['bicarbonate'],\n",
    "                                                       bins=[-np.inf, 22, 29, np.inf],\n",
    "                                                       labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['bicarbonate'], inplace=True)\n",
    "machine_learning_data['calcium_category'] = pd.cut(machine_learning_data['calcium'],\n",
    "                                                    bins=[-np.inf, 8.5, 10.2, np.inf],\n",
    "                                                    labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['calcium'], inplace=True)\n",
    "machine_learning_data['chloride_category'] = pd.cut(machine_learning_data['chloride'],\n",
    "                                                     bins=[-np.inf, 96, 107, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['chloride'], inplace=True)\n",
    "def creatinine_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [0.08, 0.9, 1.3, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [0.08, 0.91, 1.1, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['creatinine']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['creatinine_category'] = machine_learning_data.apply(creatinine_category, axis=1)\n",
    "machine_learning_data.drop(columns=['creatinine'], inplace=True)\n",
    "machine_learning_data['glucose_category'] = pd.cut(machine_learning_data['glucose'],\n",
    "                                                  bins=[-np.inf, 70, 140, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['glucose'], inplace=True)\n",
    "machine_learning_data['platelets_category'] = pd.cut(machine_learning_data['platelets'],\n",
    "                                                     bins=[-np.inf, 150, 450, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['platelets'], inplace=True)\n",
    "machine_learning_data['potassium_category'] = pd.cut(machine_learning_data['potassium'],\n",
    "                                                     bins=[-np.inf, 3.5, 5.2, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['potassium'], inplace=True)\n",
    "machine_learning_data['sodium_category'] = pd.cut(machine_learning_data['sodium'],\n",
    "                                                  bins=[-np.inf, 135, 145, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['sodium'], inplace=True)\n",
    "machine_learning_data['temperature_category'] = pd.cut(machine_learning_data['temperature'],\n",
    "                                                  bins=[-np.inf, 36.1, 37.2, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['temperature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a519389",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15221b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data = machine_learning_data.iloc[:, 2:]\n",
    "first_column = machine_learning_data.iloc[:, 0]\n",
    "machine_learning_data = machine_learning_data.iloc[:, 1:]\n",
    "machine_learning_data[first_column.name] = first_column\n",
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d438a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.to_csv('G:/共病/数据/machine_learning_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e8d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path4 = 'G:/共病/数据/machine_learning_data.csv'\n",
    "machine_learning_data = pd.read_csv(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d779dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f439e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data['community'] = machine_learning_data['community'].apply(lambda x: 0 if x == '2' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2489a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = machine_learning_data.drop('community', axis=1)\n",
    "y = machine_learning_data['community']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1aa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8409438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ed93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_predictions = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d97d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6318b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f4ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6909e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for XGBoost using GridSearchCV and cross-validation\n",
    "parameters = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ab7e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.9, 1]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.9, 1]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 0.9, 1]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(XGBClassifier(), parameters, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48587d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06271aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUROC for each model\n",
    "logreg_roc_auc = roc_auc_score(y_test, logreg_model.predict_proba(X_test)[:, 1])\n",
    "nb_roc_auc = roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1])\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "xgb_roc_auc = roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1])\n",
    "# Calculate AUROC for the best XGBoost model\n",
    "best_xgb_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Combine accuracy and AUROC results\n",
    "model_performance = {\n",
    "    'Logistic Regression': {'AUROC': logreg_roc_auc},\n",
    "    'Naive Bayes': {'AUROC': nb_roc_auc},\n",
    "    'Random Forest': {'AUROC': rf_roc_auc},\n",
    "    'XGBoost': {'AUROC': xgb_roc_auc},\n",
    "    'XGBoost with GridSearchCV': {'AUROC': best_xgb_roc_auc}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53cc3d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Logistic Regression': {'AUROC': 0.6621169180486716},\n",
       "  'Naive Bayes': {'AUROC': 0.6283672574572617},\n",
       "  'Random Forest': {'AUROC': 0.6547465567896291},\n",
       "  'XGBoost': {'AUROC': 0.6621180337214898},\n",
       "  'XGBoost with GridSearchCV': {'AUROC': 0.6762307719019475}},\n",
       " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.9})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4451a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5657943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:34:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([encoder.get_feature_names_out(), shap_sum]).T\n",
    "importance_df.columns = ['feature', 'shap_value']\n",
    "importance_df = importance_df.sort_values('shap_value', ascending=False)\n",
    "top_features = importance_df.head(15)['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8afe9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_train, feature_names=encoder.get_feature_names_out(), max_display=15, show=False)\n",
    "plt.savefig('G:/共病/图片/fig8_shap_summary_plot.png', dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2e0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
