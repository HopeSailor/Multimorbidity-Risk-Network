{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path1 = 'G:/共病/数据/multimorbidity_net_nodes_with_community_labels.csv'\n",
    "path2 = 'G:/eicu-crd/completed_data.csv'\n",
    "path3 = 'G:/eicu-crd/multimorbidity.csv'\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "df3 = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a map of ICD-10 encoding to the community\n",
    "icd_to_community = pd.Series(df1.community.values, index=df1.id).to_dict()\n",
    "\n",
    "# Step 2: Define a function to identify each patientunitstayid's community\n",
    "def determine_community(multimorbidity):\n",
    "    communities = set()\n",
    "    for icd_code in multimorbidity.split(','):\n",
    "        community = icd_to_community.get(icd_code.strip())\n",
    "        if community:\n",
    "            communities.add(str(community))  # Converts the community number to a string\n",
    "    # Combine the community into a string, separated by commas\n",
    "    return ', '.join(sorted(communities))\n",
    "\n",
    "# Step 3: Apply the function to df3\n",
    "df3['community'] = df3['multimorbidity_icd10'].apply(determine_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd551941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine_learning_data = pd.merge(df3, df2, on='patientunitstayid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45274ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data = machine_learning_data[machine_learning_data['community'] != '']\n",
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BMI\n",
    "machine_learning_data['BMI'] = machine_learning_data['weight'] / ((machine_learning_data['height'] / 100) ** 2)\n",
    "machine_learning_data = machine_learning_data.drop(columns=['height', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae525b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning based on medical experts\n",
    "machine_learning_data['age_category'] = pd.cut(machine_learning_data['age'],\n",
    "                                               bins=[0, 18, 40, 60, 80, 90, np.inf],\n",
    "                                               labels=['Children and Adolescents', 'Young Adults', 'Middle-aged', 'Senior', 'Elderly', 'Unknown'])\n",
    "machine_learning_data.drop(columns=['age'], inplace=True)\n",
    "machine_learning_data['BMI_category'] = pd.cut(machine_learning_data['BMI'],\n",
    "                                               bins=[-np.inf, 18.5, 24.9, 29.9, 34.9, 39.9, np.inf],\n",
    "                                               labels=['Underweight', 'Normal Weight', 'Overweight', 'Obesity Class I', 'Obesity Class II', 'Severe Obesity'])\n",
    "machine_learning_data.drop(columns=['BMI'], inplace=True)\n",
    "machine_learning_data['HLoS_category'] = pd.cut(machine_learning_data['HLoS'],\n",
    "                                                bins=[-np.inf, 3, 10, np.inf],\n",
    "                                                labels=['Short Stay', 'Medium Stay', 'Long Stay'])\n",
    "machine_learning_data.drop(columns=['HLoS'], inplace=True)\n",
    "machine_learning_data['ULoS_category'] = pd.cut(machine_learning_data['ULoS'],\n",
    "                                                bins=[-np.inf, 1, 3, np.inf],\n",
    "                                                labels=['Short Stay', 'Medium Stay', 'Long Stay'])\n",
    "machine_learning_data.drop(columns=['ULoS'], inplace=True)\n",
    "machine_learning_data['apachescore_category'] = pd.cut(machine_learning_data['apachescore'],\n",
    "                                                       bins=[-np.inf, 39, 69, np.inf],\n",
    "                                                       labels=['Mild', 'Moderate', 'Severe'])\n",
    "machine_learning_data.drop(columns=['apachescore'], inplace=True)\n",
    "machine_learning_data['SBP_category'] = pd.cut(machine_learning_data['SBP'],\n",
    "                                               bins=[-np.inf, 90, 120, 140, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['SBP'], inplace=True)\n",
    "machine_learning_data['DBP_category'] = pd.cut(machine_learning_data['DBP'],\n",
    "                                               bins=[-np.inf, 60, 80, 90, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['DBP'], inplace=True)\n",
    "machine_learning_data['MeanBP_category'] = pd.cut(machine_learning_data['MeanBP'],\n",
    "                                                  bins=[-np.inf, 65, 85, 100, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'Prehypertension', 'Hypertension'])\n",
    "machine_learning_data.drop(columns=['MeanBP'], inplace=True)\n",
    "machine_learning_data['sao2_category'] = pd.cut(machine_learning_data['sao2'],\n",
    "                                                bins=[-np.inf, 95, 100],\n",
    "                                                labels=['Mild Hypoxemia', 'Normal'])\n",
    "machine_learning_data.drop(columns=['sao2'], inplace=True)\n",
    "machine_learning_data['heartrate_category'] = pd.cut(machine_learning_data['heartrate'],\n",
    "                                              bins=[-np.inf, 60, 100, 156, np.inf],\n",
    "                                              labels=['Bradycardia', 'Normal', 'Tachycardia', 'Extreme Tachycardia'])\n",
    "machine_learning_data.drop(columns=['heartrate'], inplace=True)\n",
    "machine_learning_data['respiration_category'] = pd.cut(machine_learning_data['respiration'],\n",
    "                                              bins=[-np.inf, 12, 20, 38, np.inf],\n",
    "                                              labels=['Bradypnea', 'Normal', 'Tachypnea', 'Extreme Tachypnea'])\n",
    "machine_learning_data.drop(columns=['respiration'], inplace=True)\n",
    "machine_learning_data['gcsscore_category'] = pd.cut(machine_learning_data['gcsscore'],\n",
    "                                               bins=[-np.inf, 7, 13, 15],\n",
    "                                               labels=['Severe Coma', 'Moderate Coma', 'Alert'])\n",
    "machine_learning_data.drop(columns=['gcsscore'], inplace=True)\n",
    "machine_learning_data['Urine_category'] = pd.cut(machine_learning_data['Urine'],\n",
    "                                              bins=[-np.inf, 500, 1477, np.inf],\n",
    "                                              labels=['Low Output', 'Normal', 'High Output'])\n",
    "machine_learning_data.drop(columns=['Urine'], inplace=True)\n",
    "machine_learning_data['BUN_category'] = pd.cut(machine_learning_data['BUN'],\n",
    "                                               bins=[-np.inf, 20, 83, np.inf],\n",
    "                                               labels=['Normal', 'Elevated', 'Very High'])\n",
    "machine_learning_data.drop(columns=['BUN'], inplace=True)\n",
    "machine_learning_data['Hct_category'] = pd.cut(machine_learning_data['Hct'],\n",
    "                                               bins=[-np.inf, 37, 50, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['Hct'], inplace=True)\n",
    "def hgb_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [2, 11, 16, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [2, 11, 15, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['Hgb']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['Hgb_category'] = machine_learning_data.apply(hgb_category, axis=1)\n",
    "machine_learning_data.drop(columns=['Hgb'], inplace=True)\n",
    "machine_learning_data['MCH_category'] = pd.cut(machine_learning_data['MCH'],\n",
    "                                               bins=[-np.inf, 27, 32, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCH'], inplace=True)\n",
    "machine_learning_data['MCHC_category'] = pd.cut(machine_learning_data['MCHC'],\n",
    "                                                bins=[-np.inf, 32, 36, np.inf],\n",
    "                                                labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCHC'], inplace=True)\n",
    "machine_learning_data['MCV_category'] = pd.cut(machine_learning_data['MCV'],\n",
    "                                               bins=[-np.inf, 86, 98, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MCV'], inplace=True)\n",
    "machine_learning_data['MPV_category'] = pd.cut(machine_learning_data['MPV'],\n",
    "                                               bins=[-np.inf, 8, 12, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['MPV'], inplace=True)\n",
    "def rbc_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [0.7, 3.1, 5.4, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [0.7, 3.2, 4.8, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['RBC']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['RBC_category'] = machine_learning_data.apply(rbc_category, axis=1)\n",
    "machine_learning_data.drop(columns=['RBC'], inplace=True)\n",
    "machine_learning_data['RDW_category'] = pd.cut(machine_learning_data['RDW'],\n",
    "                                               bins=[-np.inf, 13, np.inf],\n",
    "                                               labels=['Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['RDW'], inplace=True)\n",
    "machine_learning_data['WBC_category'] = pd.cut(machine_learning_data['WBC'],\n",
    "                                               bins=[-np.inf, 4, 10, np.inf],\n",
    "                                               labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['WBC'], inplace=True)\n",
    "machine_learning_data['AnionGap_category'] = pd.cut(machine_learning_data['AnionGap'],\n",
    "                                              bins=[-np.inf, 7, 16, np.inf],\n",
    "                                              labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['AnionGap'], inplace=True)\n",
    "machine_learning_data['BG_category'] = pd.cut(machine_learning_data['BG'],\n",
    "                                              bins=[-np.inf, 70, 140, np.inf],\n",
    "                                              labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['BG'], inplace=True)\n",
    "machine_learning_data['bicarbonate_category'] = pd.cut(machine_learning_data['bicarbonate'],\n",
    "                                                       bins=[-np.inf, 22, 29, np.inf],\n",
    "                                                       labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['bicarbonate'], inplace=True)\n",
    "machine_learning_data['calcium_category'] = pd.cut(machine_learning_data['calcium'],\n",
    "                                                    bins=[-np.inf, 8.5, 10.2, np.inf],\n",
    "                                                    labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['calcium'], inplace=True)\n",
    "machine_learning_data['chloride_category'] = pd.cut(machine_learning_data['chloride'],\n",
    "                                                     bins=[-np.inf, 96, 107, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['chloride'], inplace=True)\n",
    "def creatinine_category(row):\n",
    "    if row['gender'] == 'Male':\n",
    "        bins = [0.08, 0.9, 1.3, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    else:\n",
    "        bins = [0.08, 0.91, 1.1, np.inf]\n",
    "        labels = ['Low', 'Normal', 'High']\n",
    "    return pd.cut([row['creatinine']], bins=bins, labels=labels)[0]\n",
    "machine_learning_data['creatinine_category'] = machine_learning_data.apply(creatinine_category, axis=1)\n",
    "machine_learning_data.drop(columns=['creatinine'], inplace=True)\n",
    "machine_learning_data['glucose_category'] = pd.cut(machine_learning_data['glucose'],\n",
    "                                                  bins=[-np.inf, 70, 140, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['glucose'], inplace=True)\n",
    "machine_learning_data['platelets_category'] = pd.cut(machine_learning_data['platelets'],\n",
    "                                                     bins=[-np.inf, 150, 450, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['platelets'], inplace=True)\n",
    "machine_learning_data['potassium_category'] = pd.cut(machine_learning_data['potassium'],\n",
    "                                                     bins=[-np.inf, 3.5, 5.2, np.inf],\n",
    "                                                     labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['potassium'], inplace=True)\n",
    "machine_learning_data['sodium_category'] = pd.cut(machine_learning_data['sodium'],\n",
    "                                                  bins=[-np.inf, 135, 145, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['sodium'], inplace=True)\n",
    "machine_learning_data['temperature_category'] = pd.cut(machine_learning_data['temperature'],\n",
    "                                                  bins=[-np.inf, 36.1, 37.2, np.inf],\n",
    "                                                  labels=['Low', 'Normal', 'High'])\n",
    "machine_learning_data.drop(columns=['temperature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a519389",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_counts = machine_learning_data['community'].value_counts()\n",
    "community_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15221b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data = machine_learning_data.iloc[:, 2:]\n",
    "first_column = machine_learning_data.iloc[:, 0]\n",
    "machine_learning_data = machine_learning_data.iloc[:, 1:]\n",
    "machine_learning_data[first_column.name] = first_column\n",
    "machine_learning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38787691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "machine_learning_data['community'] = machine_learning_data['community'].apply(lambda x: x.split(', '))\n",
    "machine_learning_data = machine_learning_data.join(pd.DataFrame(mlb.fit_transform(machine_learning_data.pop('community')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=machine_learning_data.index))\n",
    "columns = list(machine_learning_data.columns[:-3]) + ['community1', 'community2', 'community3']\n",
    "machine_learning_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d438a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_data.to_csv('G:/共病/数据/machine_learning_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path4 = 'G:/共病/数据/machine_learning_data.csv'\n",
    "machine_learning_data = pd.read_csv(path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and labels\n",
    "X = machine_learning_data.iloc[:, :-3]  # All columns except the last three\n",
    "y = machine_learning_data[['community1', 'community2', 'community3']]  # The last three columns are the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "mlp = MLPClassifier(random_state=42, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Chains with a base estimator\n",
    "classifier_chain_dt = ClassifierChain(decision_tree, order='random', random_state=42)\n",
    "classifier_chain_rf = ClassifierChain(random_forest, order='random', random_state=42)\n",
    "classifier_chain_mlp = ClassifierChain(mlp, order='random', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models\n",
    "classifier_chain_dt.fit(X_train, y_train)\n",
    "classifier_chain_rf.fit(X_train, y_train)\n",
    "classifier_chain_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6909e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_dt = classifier_chain_dt.predict(X_test)\n",
    "y_pred_rf = classifier_chain_rf.predict(X_test)\n",
    "y_pred_mlp = classifier_chain_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F1 scores\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='micro')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='micro')\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree F1 Scores by Label:\")\n",
    "report_dt = classification_report(y_test, y_pred_dt, target_names=['Community 1', 'Community 2', 'Community 3'], output_dict=True)\n",
    "for label, metrics in report_dt.items():\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            metrics[metric] = round(value, 4)\n",
    "print(report_dt)\n",
    "\n",
    "\n",
    "print(\"Random Forest F1 Scores by Label:\")\n",
    "report_rf = classification_report(y_test, y_pred_rf, target_names=['Community 1', 'Community 2', 'Community 3'], output_dict=True)\n",
    "for label, metrics in report_rf.items():\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            metrics[metric] = round(value, 4)\n",
    "print(report_rf)\n",
    "\n",
    "print(\"MLP F1 Scores by Label:\")\n",
    "report_mlp = classification_report(y_test, y_pred_mlp, target_names=['Community 1', 'Community 2', 'Community 3'], output_dict=True)\n",
    "for label, metrics in report_mlp.items():\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            metrics[metric] = round(value, 4)\n",
    "print(report_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = 2  # Modify this index to analyze different tags\n",
    "rf_model = classifier_chain_rf.estimators_[label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_sample to a DataFrame\n",
    "X_sample_df = pd.DataFrame(X_test[:100], columns=encoder.get_feature_names_out())\n",
    "# Ensure your sample has the correct shape and features\n",
    "X_sample_df = X_sample_df.reindex(columns=encoder.get_feature_names_out(), fill_value=0)\n",
    "# Convert X_sample_df back to a NumPy array (if necessary)\n",
    "X_sample = X_sample_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer with interventional feature perturbation\n",
    "explainer = shap.TreeExplainer(rf_model, feature_perturbation='interventional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb70a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SHAP values with additivity check disabled\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if shap_values is a list (multi-output model)\n",
    "if isinstance(shap_values, list):\n",
    "    # Aggregate SHAP values across outputs (e.g., summing absolute values)\n",
    "    shap_values = np.sum(np.abs(shap_values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute SHAP values for feature importance\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "# Verify shapes\n",
    "print(\"Shape of shap_sum:\", shap_sum.shape)\n",
    "print(\"Shape of feature names:\", encoder.get_feature_names_out().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5657943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': encoder.get_feature_names_out(),\n",
    "    'shap_value': shap_sum\n",
    "})\n",
    "importance_df = importance_df.sort_values('shap_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 15 features with their SHAP values\n",
    "top_features = importance_df.head(15)\n",
    "print(top_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
